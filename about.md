  ‚è∫ # Grokputer Project

	Grokputer is an AI-powered project for deploying and optimizing an MCP (Model Context Protocol) server, featuring tools for secure vault scanning, shell
    execution, and data retrieval, with integrations for fine-tuning models like Qwen Coder and Llama for OCR tasks. Built using FastMCP, Docker, Redis for
    memory management, and Python, it emphasizes security fixes against shell injection, high-performance message handling (up to 28k+ messages/sec), and swarm
     AI for tasks and generating training data. The project includes comprehensive testing, autonomous operations, and deployment capabilities for cloud environments.

    ## Quick Start

        1. **Install Deps**: `pip install -r requirements.txt` (includes FastMCP,
     uvicorn, peft, transformers, etc.).
        2. **Build MCP**: `build-mcp.bat` (creates Docker image).
        3. **Run Containers**: `docker-compose up -d` (starts MCP on 8000, Redis
    on 6379).
        4. **Test Tools**: Curl http://localhost:8000/grokputer/scan_vault (scans
     vault/).
        5. **Fine-Tune**: `python src/finetune_qwen_coder.py --data_path
    data/finetune_ocr.jsonl --epochs 3`.

    ## Features

        * **MCP Server**: 4 tools (scan_vault, invoke_prayer, get_vault_stats,
    safe_shell_exec) with async support.
        * **Security**: Shell injection fixed (executor.py uses shell=False +
    whitelist).
        * **Memory**: Redis-backed store with TTL; MessageBus for pub/sub.
        * **OCR**: Llama-based extraction (fine-tuned on vault/PDFs).
        * **Swarm**: Task generation for training data (e.g., OCR prompts).
        * **Tests**: 8+ unit/integration tests (all passing).

    ## Performance

        * MessageBus: Up to 28k+ msgs/sec (with multiprocessing and async
    optimizations in in-memory mode; scales with cores; Redis mode ~14k for
    persistence).
        * Setup: Run tests/test_messagebus_live.py --analytics --optimize
    --multiprocess for benchmarks.

    ## Directory Structure

        * **docs/**: Documentation (sessions, plans, updates).
        * **src/**: Core code (executor.py, llama_ocr.py, finetune scripts).
        * **tests/**: Unit tests (test_messagebus_live.py,
    test_ocr_integration.py).
        * **data/**: Training datasets (finetune_ocr.jsonl).
        * **models/**: Fine-tuned adapters (qwen_coder_pdfs_adapter).
        * **vault/**: Data files (PDF/ for OCR training).

    ## Next Steps

        * Expand swarm for more data gen.
        * Deploy to cloud.
        * Fine-tune additional models.

    Session End: Project optimized and ready. LFG!
